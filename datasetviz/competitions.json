[
    {
        "datasetId": 5001,
        "datasetTitle": "HMDB51",
        "datasetDescription": "HMDB: A Large Video Database for Human Motion Recognition",
        "websiteUrl": "http://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/",
        "thumbnailImageUrl": "http://www.di.ens.fr/~miech/hmdb.PNG",
		"paperUrl": "http://serre-lab.clps.brown.edu/wp-content/uploads/2012/08/Kuehne_etal_iccv11.pdf",
        "publishedYear": 2011,
        "type": "Action recognition",
        "numberOfVideos": 6766,
        "annotation": "51 action classes",
        "annotationType": ["pre-defined classes"],
        "comment": "..."
    },
	{
        "datasetId": 5002,
        "datasetTitle": "UCF101",
        "datasetDescription": "UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild",
        "websiteUrl": "http://crcv.ucf.edu/data/UCF101.php",
        "thumbnailImageUrl": "https://ai2-s2-public.s3.amazonaws.com/figures/2016-11-08/450e8bb9c67e731ffd4afb80e11dcf7cad99904a/1-Figure1-1.png",
		"paperUrl": "http://crcv.ucf.edu/papers/UCF101_CRCV-TR-12-01.pdf",
        "publishedYear": 2012,
        "type": "Sports",
        "numberOfVideos": 13320,
        "annotation": "101 action classes",
        "annotationType": ["pre-defined classes"],
        "comment": "..."
    },
	{
        "datasetId": 5003,
        "datasetTitle": "Sports-1M",
        "datasetDescription": "The YouTube Sports-1M Dataset",
        "websiteUrl": "http://cs.stanford.edu/people/karpathy/deepvideo/",
        "thumbnailImageUrl": "https://lh3.googleusercontent.com/proxy/gC6TPBC9tRjxnV2ukljoWpyaHzpCHpSS0LsDuB640DaoIO9MOgHwzxD6WmJIkPXpax2vOiSIGfP2hZr35eo4dz48Rg=w530-h298-p",
		"paperUrl": "http://cs.stanford.edu/people/karpathy/deepvideo/deepvideo_cvpr2014.pdf",
        "publishedYear": 2014,
        "type": "Sports",
        "numberOfVideos": 1100000,
        "annotation": "487 sports classes",
        "annotationType": ["pre-defined classes"],
        "comment": "Youtube URLs"
    },
	{
        "datasetId": 5004,
        "datasetTitle": "Charades",
        "datasetDescription": "This dataset guides our research into unstructured video activity recognition and commonsense reasoning for daily human activities",
        "websiteUrl": "http://allenai.org/plato/charades/",
        "thumbnailImageUrl": "http://www.di.ens.fr/~varol/img/charades.jpg",
		"paperUrl": "https://arxiv.org/pdf/1604.01753.pdf",
        "publishedYear": 2016,
        "type": "Human activities",
        "numberOfVideos": 9848,
        "annotation": "157 action labels, 27847 Free-text descriptions, action intervals, classes of interacted objects",
        "annotationType": ["pre-defined classes", "text", "intervals"],
        "comment": "..."
    },
	{
        "datasetId": 5005,
        "datasetTitle": "ActivityNet",
        "datasetDescription": "A Large-Scale Video Benchmark for Human Activity Understanding",
        "websiteUrl": "http://activity-net.org/",
        "thumbnailImageUrl": "http://www.di.ens.fr/~miech/activitynet.PNG",
		"paperUrl": "http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Heilbron_ActivityNet_A_Large-Scale_2015_CVPR_paper.pdf",
        "publishedYear": 2015,
        "type": "Human activities",
        "numberOfVideos": 28000,
        "annotation": "203 classes",
        "annotationType": ["pre-defined classes"],
        "comment": "..."
    },
	{
        "datasetId": 5006,
        "datasetTitle": "Kinetics",
        "datasetDescription": "Kinetics is a large-scale, high-quality dataset of YouTube video URLs which include a diverse range of human focused actions",
        "websiteUrl": "https://deepmind.com/research/open-source/open-source-datasets/kinetics/",
        "thumbnailImageUrl": "https://deepmind.com/static/v0.0.0/images/deepmind_logo.png",
		"paperUrl": "https://arxiv.org/abs/1705.06950",
        "publishedYear": 2017,
        "type": "Action Recognition",
        "numberOfVideos": 500000,
        "annotation": "600 action classes",
        "annotationType": ["pre-defined classes"],
        "comment": "Youtube URLs"
    },
	{
        "datasetId": 5007,
        "datasetTitle": "Youtube-8M",
        "datasetDescription": "YouTube-8M is a large-scale labeled video dataset that consists of millions of YouTube video IDs and associated labels from a diverse vocabulary of 4700+ visual entities",
        "websiteUrl": "https://research.google.com/youtube8m/download.html",
        "thumbnailImageUrl": "https://2.bp.blogspot.com/-5j8jdVargFc/WxXrZC-y-XI/AAAAAAAACw8/LqIAodOQIYYWZLD2ka2UojYTq3uAy12tQCLcBGAs/s1600/image1.jpg",
		"paperUrl": "https://arxiv.org/abs/1609.08675",
        "publishedYear": 2016,
        "type": "Youtube Random Videos",
        "numberOfVideos": 8000000,
        "annotation": "4716 classes",
        "annotationType": ["pre-defined classes"],
        "comment": "Youtube URLs"
    },
	{
        "datasetId": 5008,
        "datasetTitle": "AVA",
        "datasetDescription": "A Video Dataset of Spatio-temporally Localized Atomic Visual Actions",
        "websiteUrl": "https://research.google.com/ava/",
        "thumbnailImageUrl": "http://www.di.ens.fr/~miech/ava.PNG",
		"paperUrl": "https://arxiv.org/abs/1705.08421",
        "publishedYear": 2017,
        "type": "Atomic visual actions",
        "numberOfVideos": 57600,
        "annotation": "210k action labels, 80 atomic visual actions, spatio-temporal annotations",
        "annotationType": ["pre-defined classes", "text", "spatio-temporal annotation"],
        "comment": "..."
    },
	{
        "datasetId": 5009,
        "datasetTitle": "20BN-SOMETHING-SOMETHING",
        "datasetDescription": "The 20BN-SOMETHING-SOMETHING dataset is a large collection of densly-labeled video clips that show humans performing predefined basic actions with every day objects",
        "websiteUrl": "https://www.twentybn.com/datasets/something-something",
        "thumbnailImageUrl": "http://www.di.ens.fr/~miech/somethingsomething.PNG",
		"paperUrl": "https://arxiv.org/abs/1706.04261",
        "publishedYear": 2017,
        "type": "Human activities",
        "numberOfVideos": 108000,
        "annotation": "174 classes",
        "annotationType": ["pre-defined classes"],
        "comment": "..."
    },
	{
        "datasetId": 5010,
        "datasetTitle": "20BN-JESTER",
        "datasetDescription": "Human Hand Gestures Dataset",
        "websiteUrl": "https://www.twentybn.com/datasets/jester",
        "thumbnailImageUrl": "https://www.twentybn.com/assets/homepage/blog/swiping_left-4d9a4335d24f3149827e79e6031186e480916a51a761f3f48df2d560afc8e845.png",
		"paperUrl": "/",
        "publishedYear": 2017,
        "type": "Hand Gestures",
        "numberOfVideos": 148000,
        "annotation": "27 classes",
        "annotationType": ["pre-defined classes"],
        "comment": "..."
    },
	{
        "datasetId": 5011,
        "datasetTitle": "LSMDC",
        "datasetDescription": "Large-Scale Movie Understanding Dataset",
        "websiteUrl": "http://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/research/vision-and-language/mpii-movie-description-dataset/",
        "thumbnailImageUrl": "https://www.mpi-inf.mpg.de/fileadmin/_processed_/7/b/csm_cvpr15-teaser_03ed84492a.png",
		"paperUrl": "https://arxiv.org/pdf/1605.03705.pdf",
        "publishedYear": 2015,
        "type": "Movie clips",
        "numberOfVideos": 118000,
        "annotation": "Aligned captions",
        "annotationType": ["text"],
        "comment": "..."
    },
	{
        "datasetId": 5012,
        "datasetTitle": "DALY",
        "datasetDescription": "Daily Action Localization in Youtube videos ",
        "websiteUrl": "http://thoth.inrialpes.fr/daly/",
        "thumbnailImageUrl": "http://thoth.inrialpes.fr/daly/images/examples/phoning.png",
		"paperUrl": "https://arxiv.org/pdf/1605.05197.pdf",
        "publishedYear": 2016,
        "type": "Spatio-temporal Action localization",
        "numberOfVideos": 8100,
        "annotation": "3.6k spatio-temporal action annotation",
        "annotationType": ["pre-defined classes","spatio-temporal annotation"],
        "comment": "..."
    },
	{
        "datasetId": 5013,
        "datasetTitle": "MPII-Cooking",
        "datasetDescription": "MPII Cooking dataset",
        "websiteUrl": "https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/research/human-activity-recognition/mpii-cooking-2-dataset/",
        "thumbnailImageUrl": "https://www.researchgate.net/profile/Hilde_Kuehne/publication/281607579/figure/fig2/AS:284604436107265@1444866393122/Figure-4-Sample-results-for-segmentation-for-a-the-ADL-dataset-dial-phone-b-the.png",
		"paperUrl": "https://www.mpi-inf.mpg.de/fileadmin/inf/d2/amin/rohrbach12cvpr.pdf",
        "publishedYear": 2012,
        "type": "Cooking videos",
        "numberOfVideos": 273,
        "annotation": "78 classes, 13k labelled instances",
        "annotationType": ["pre-defined classes", "text"],
        "comment": "..."
    },
	{
        "datasetId": 5014,
        "datasetTitle": "Hollywood2",
        "datasetDescription": "Human Actions and Scenes Dataset",
        "websiteUrl": "http://www.di.ens.fr/~laptev/actions/hollywood2/",
        "thumbnailImageUrl": "http://www.di.ens.fr/~laptev/actions/humact.jpg",
		"paperUrl": "http://www.irisa.fr/vista/Papers/2009_cvpr_marszalek.pdf",
        "publishedYear": 2009,
        "type": "Action recognition",
        "numberOfVideos": 3669,
        "annotation": "12 human action classes, 10 classes of scene",
        "annotationType": ["pre-defined classes"],
        "comment": "..."
    },
	{
        "datasetId": 5015,
        "datasetTitle": "VideoMCC",
        "datasetDescription": "a New Benchmark for Video Comprehension",
        "websiteUrl": "http://videomcc.org/",
        "thumbnailImageUrl": "http://www.di.ens.fr/~miech/vicom.PNG",
		"paperUrl": "https://arxiv.org/abs/1606.07373",
        "publishedYear": 2016,
        "type": "Video News Understanding",
        "numberOfVideos": 272000,
        "annotation": "10 topics and Video captions",
        "annotationType": ["Question-Answer","text"],
        "comment": "..."
    },
	{
        "datasetId": 5016,
        "datasetTitle": "MovieQA",
        "datasetDescription": "A Question Answering data set for Automatic Story Comprehension",
        "websiteUrl": "http://movieqa.cs.toronto.edu/home/",
        "thumbnailImageUrl": "http://www.cs.utoronto.ca/~fidler/papers/figs/movieqa.jpg",
		"paperUrl": "http://movieqa.cs.toronto.edu/static/files/CVPR2016_MovieQA.pdf",
        "publishedYear": 2016,
        "type": "Movie Understanding",
        "numberOfVideos": 140,
        "annotation": "15k Question-Answer, 408 movie plots, 408 subtitles",
        "annotationType": ["Question-Answer","text"],
        "comment": "..."
    },
	{
        "datasetId": 5017,
        "datasetTitle": "ActivityNet Captions",
        "datasetDescription": "a large-scale benchmark for dense-captioning events",
        "websiteUrl": "http://cs.stanford.edu/people/ranjaykrishna/densevid/",
        "thumbnailImageUrl": "http://cs.stanford.edu/people/ranjaykrishna/densevid/prediction2.png",
		"paperUrl": "https://arxiv.org/abs/1705.00754",
        "publishedYear": 2017,
        "type": "Captioning",
        "numberOfVideos": 20000,
        "annotation": "100k Aligned captions",
        "annotationType": ["text"],
        "comment": "..."
    },
	{
        "datasetId": 5018,
        "datasetTitle": "Youtube BoundingBoxes",
        "datasetDescription": "YouTube-BoundingBoxes Dataset",
        "websiteUrl": "https://research.google.com/youtube-bb/",
        "thumbnailImageUrl": "http://www.di.ens.fr/~miech/bb.PNG",
		"paperUrl": "https://arxiv.org/abs/1702.00824",
        "publishedYear": 2017,
        "type": "Spatio-temporal object bounding boxes",
        "numberOfVideos": 240000,
        "annotation": "5.6M Bouding boxes, 23 objects",
        "annotationType": ["Bounding boxes"],
        "comment": "..."
    },
	{
        "datasetId": 5019,
        "datasetTitle": "DAVIS",
        "datasetDescription": "Densely Annotated VIdeo Segmentation",
        "websiteUrl": "http://davischallenge.org/",
        "thumbnailImageUrl": "http://davischallenge.org/images/teaser/montage-2017.jpg",
		"paperUrl": "http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Perazzi_A_Benchmark_Dataset_CVPR_2016_paper.pdf",
        "publishedYear": 2016,
        "type": "Spatio-temporal object segmentation",
        "numberOfVideos": 50,
        "annotation": "3455 annotated frames",
        "annotationType": ["Segmentation mask"],
        "comment": "..."
    },
	{
        "datasetId": 5020,
        "datasetTitle": "FCVID",
        "datasetDescription": "Fudan-Columbia Video Dataset",
        "websiteUrl": "http://bigvid.fudan.edu.cn/FCVID/",
        "thumbnailImageUrl": "http://www.di.ens.fr/~miech/fcvid.PNG",
	"paperUrl": "https://arxiv.org/abs/1502.07209",
        "publishedYear": 2015,
        "type": "Human activities, scene and objects",
        "numberOfVideos": 91223,
        "annotation": "239 classes",
        "annotationType": ["pre-defined classes"],
        "comment": "..."
    },
	{
        "datasetId": 5021,
        "datasetTitle": "VGG Human Pose",
        "datasetDescription": "The VGG Human Pose Estimation datasets is a set of large video datasets annotated with human upper-body pose",
        "websiteUrl": "https://www.robots.ox.ac.uk/~vgg/data/pose/index.html",
        "thumbnailImageUrl": "https://www.robots.ox.ac.uk/~vgg/data/pose/array.png",
	"paperUrl": "https://arxiv.org/abs/1511.06676",
        "publishedYear": 2013,
        "type": "Human Pose Estimation",
        "numberOfVideos": 152,
        "annotation": "Hours of human upper-body pose",
        "annotationType": ["human pose"],
        "comment": "..."
    },
	{
        "datasetId": 5022,
        "datasetTitle": "YFCC100M",
        "datasetDescription": "YFCC100M: The New Data in Multimedia Research",
        "websiteUrl": "http://yfcc100m.appspot.com/?",
        "thumbnailImageUrl": "https://cdn.ghacks.net/wp-content/uploads/2008/08/flickr_video_browser-499x331.jpg",
	"paperUrl": "https://arxiv.org/pdf/1503.01817.pdf",
        "publishedYear": 2015,
        "type": "Webly annotated Flickr videos",
        "numberOfVideos": 800000,
        "annotation": "1570 tags, captions and diverse metadata",
        "annotationType": ["Captions", "pre-defined classes"],
        "comment": "Also contains 99 Millions of webly annotated images"
    },	
	{
        "datasetId": 5023,
        "datasetTitle": "ASLAN",
        "datasetDescription": "The Action Similarity Labeling dataset",
        "websiteUrl": "http://www.openu.ac.il/home/hassner/data/ASLAN/ASLAN.html",
        "thumbnailImageUrl": "http://www.openu.ac.il/home/hassner/data/ASLAN/img/aslanlogo.jpg",
	"paperUrl": "http://www.openu.ac.il/home/hassner/data/ASLAN/Papers/ASLAN_TPAMI12.pdf",
        "publishedYear": 2012,
        "type": "Action recognition",
        "numberOfVideos": 1571,
        "annotation": "432 action classes, 3697 action samples",
        "annotationType": ["pre-defined classes"],
        "comment": "..."
    },	
	{
        "datasetId": 5024,
        "datasetTitle": "Instruction video dataset",
        "datasetDescription": "A new challenging dataset of real-world instruction videos from the Internet",
        "websiteUrl": "http://www.di.ens.fr/willow/research/instructionvideos/",
        "thumbnailImageUrl": "http://www.di.ens.fr/willow/research/instructionvideos/images/teaser.png",
	"paperUrl": "http://arxiv.org/abs/1506.09215",
        "publishedYear": 2016,
        "type": "Instructions videos",
        "numberOfVideos": 150,
        "annotation": "5 different instructional tasks with subtitles",
        "annotationType": ["pre-defined classes", "captions"],
        "comment": "..."
    },	
	{
        "datasetId": 5025,
        "datasetTitle": "DiDeMo dataset",
        "datasetDescription": "the Distinct Describable Moments (DiDeMo) dataset consists of over 10,000 unedited, personal videos in diverse visual settings with pairs of localized video segments and referring expressions.",
        "websiteUrl": "https://people.eecs.berkeley.edu/%7Elisa_anne/didemo.html",
        "thumbnailImageUrl": "http://www.di.ens.fr/~miech/datasetviz/didemo.png",
	"paperUrl": "http://arxiv.org/abs/1506.09215",
        "publishedYear": 2017,
        "type": "Captioning",
        "numberOfVideos": 10000,
        "annotation": "40000 aligned captions",
        "annotationType": ["captions"],
        "comment": "..."
    },	
	{
        "datasetId": 5026,
        "datasetTitle": "MSR-VTT",
        "datasetDescription": "A Large Video Description Dataset for Bridging Video and Language",
        "websiteUrl": "https://www.microsoft.com/en-us/research/publication/msr-vtt-a-large-video-description-dataset-for-bridging-video-and-language/",
        "thumbnailImageUrl": "https://winbuzzer.com/wp-content/uploads/2016/06/Microsoft-Research-Video-Language.jpg",
	"paperUrl": "https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/cvpr16.msr-vtt.tmei_-1.pdf",
        "publishedYear": 2016,
        "type": "Captioning",
        "numberOfVideos": 10000,
        "annotation": "200000 aligned captions",
        "annotationType": ["captions"],
        "comment": "..."
    },	
	{
        "datasetId": 5027,
        "datasetTitle": "HACS",
        "datasetDescription": "Human Action Clips and Segments Dataset for Recognition and Temporal Localization",
        "websiteUrl": "http://hacs.csail.mit.edu/",
        "thumbnailImageUrl": "http://www.mit.edu/~hangzhao/images/slac.jpg",
	"paperUrl": "https://arxiv.org/abs/1712.09374",
        "publishedYear": 2017,
        "type": "Action recognition",
        "numberOfVideos": 520000,
        "annotation": "200 action classes, 1.75M clip annotations",
        "annotationType": ["pre-defined classes"],
        "comment": "..."
    },	
	{
        "datasetId": 5028,
        "datasetTitle": "VLOG",
        "datasetDescription": "From Lifestyle VLOGs to Everyday Interactions: The VLOG Dataset",
        "websiteUrl": "https://people.eecs.berkeley.edu/~dfouhey/2017/VLOG/index.html",
        "thumbnailImageUrl": "https://people.eecs.berkeley.edu/~dfouhey/2017/VLOG/assets/webteaser.jpg",
	"paperUrl": "https://arxiv.org/abs/1712.02310",
        "publishedYear": 2017,
        "type": "Action recognition",
        "numberOfVideos": 114000,
        "annotation": "",
        "annotationType": ["pre-defined classes"],
        "comment": "..."
    },	
	{
        "datasetId": 5029,
        "datasetTitle": "Moments in Time",
        "datasetDescription": "Moments in Time Dataset: one million videos for event understanding",
        "websiteUrl": "http://moments.csail.mit.edu/",
        "thumbnailImageUrl": "http://carlvondrick.com/moments.gif",
	"paperUrl": "https://arxiv.org/abs/1801.03150",
        "publishedYear": 2017,
        "type": "Action recognition",
        "numberOfVideos": 1000000,
        "annotation": "339 action classes",
        "annotationType": ["pre-defined classes"],
        "comment": "..."
    },	
	{
        "datasetId": 5030,
        "datasetTitle": "YouCook2",
        "datasetDescription": "YouCook2 is the largest task-oriented, instructional video dataset in the vision community",
        "websiteUrl": "http://youcook2.eecs.umich.edu/",
        "thumbnailImageUrl": "http://youcook2.eecs.umich.edu/static/images/yc2.png",
	"paperUrl": "https://arxiv.org/pdf/1703.09788.pdf",
        "publishedYear": 2018,
        "type": "Cooking videos",
        "numberOfVideos": 2000,
        "annotation": "15400 aligned captions",
        "annotationType": ["captions"],
        "comment": "..."
    },	
	{
        "datasetId": 5031,
        "datasetTitle": "EPIC-KITCHENS",
        "datasetDescription": "The largest dataset in first-person (egocentric) vision; multi-faceted non-scripted recordings in native environments - i.e. the wearers' homes, capturing all daily activities in the kitchen over multiple days. ",
        "websiteUrl": "https://epic-kitchens.github.io/2018",
        "thumbnailImageUrl": "https://epic-kitchens.github.io/static/img/stats-figures/challenge1.png",
	"paperUrl": "https://arxiv.org/pdf/1804.02748.pdf",
        "publishedYear": 2018,
        "type": "Cooking videos",
        "numberOfVideos": 432,
        "annotation": "39596 action segments, 323 object classes, 454,158 bounding boxes",
        "annotationType": ["pre-defined classes"],
        "comment": "..."
    },	
	{
        "datasetId": 5032,
        "datasetTitle": "How2",
        "datasetDescription": "How2 is a multimodal collection of instructional videos with English subtitles and crowdsourced Portuguese translations.",
        "websiteUrl": "https://github.com/srvk/how2-dataset",
        "thumbnailImageUrl": "https://srvk.github.io/how2-challenge/img/How2_Image-2.png",
	"paperUrl": "https://arxiv.org/pdf/1811.00347.pdf",
        "publishedYear": 2018,
        "type": "Instructions videos",
        "numberOfVideos": 13168,
        "annotation": "184949 aligned captions",
        "annotationType": ["captions"],
        "comment": "..."
    },	
	{
        "datasetId": 5033,
        "datasetTitle": "COIN",
        "datasetDescription": "A large-scale dataset for COmprehensive INstructional video analysis. ",
        "websiteUrl": "https://coin-dataset.github.io/",
        "thumbnailImageUrl": "https://coin-dataset.github.io/img/logo_black_0313.png",
	"paperUrl": "https://arxiv.org/pdf/1903.02874.pdf",
        "publishedYear": 2019,
        "type": "Instructions videos",
        "numberOfVideos": 11827,
        "annotation": "180 tasks, 46354 action segments",
        "annotationType": ["pre-defined classes"],
        "comment": "..."
    },	
	{
        "datasetId": 5034,
        "datasetTitle": "CrossTask",
        "datasetDescription": "CrossTasks is an instructional videos dataset.",
        "websiteUrl": "https://github.com/DmZhukov/CrossTask",
        "thumbnailImageUrl": "https://www.rocq.inria.fr/cluster-willow/amiech/crosstask.png",
	"paperUrl": "https://arxiv.org/pdf/1903.08225.pdf",
        "publishedYear": 2019,
        "type": "Instructions videos",
        "numberOfVideos": 4700,
        "annotation": "83 tasks",
        "annotationType": ["pre-defined classes"],
        "comment": "..."
    },	
	{
        "datasetId": 5035,
        "datasetTitle": "VATEX",
        "datasetDescription": "VATEX is a multilingual video description dataset.",
        "websiteUrl": "https://eric-xw.github.io/vatex-website/",
        "thumbnailImageUrl": "https://www.rocq.inria.fr/cluster-willow/amiech/vatex.png",
	"paperUrl": "https://arxiv.org/pdf/1904.03493.pdf",
        "publishedYear": 2019,
        "type": "Captioning",
        "numberOfVideos": 41250,
        "annotation": "400000 aligned English captions, 400000 aligned Chinese captions ",
        "annotationType": ["captions"],
        "comment": "..."
    },	
	{
        "datasetId": 5036,
        "datasetTitle": "MovieGraphs",
        "datasetDescription": "MovieGraphs provides detailed graph-based annotations of social situations depicted in movie clips.",
        "websiteUrl": "http://moviegraphs.cs.toronto.edu/",
        "thumbnailImageUrl": "http://moviegraphs.cs.toronto.edu/static/images/MovieGraphsCutLogo.png",
	"paperUrl": "https://arxiv.org/pdf/1712.06761.pdf",
        "publishedYear": 2018,
        "type": "Movie clips",
        "numberOfVideos": 7637,
        "annotation": "Social situation graph",
        "annotationType": ["graph"],
        "comment": "..."
    },	
	{
        "datasetId": 5037,
        "datasetTitle": "TGIF",
        "datasetDescription": "Tumblr GIF description dataset",
        "websiteUrl": "http://raingo.github.io/TGIF-Release/",
        "thumbnailImageUrl": "https://66.media.tumblr.com/9f659499c8754e40cf3f7ac21d08dae6/tumblr_nqlr0rn8ox1r2r0koo1_400.gif",
	"paperUrl": "https://arxiv.org/pdf/1604.02748.pdf",
        "publishedYear": 2016,
        "type": "GIF captioning",
        "numberOfVideos": 125781,
        "annotation": "125781 captions",
        "annotationType": ["captions"],
        "comment": "..."
    },	
	{
        "datasetId": 5038,
        "datasetTitle": "HowTo100M",
        "datasetDescription": "A large scale dataset of narrated instructional web videos",
        "websiteUrl": "https://www.di.ens.fr/willow/research/howto100m/",
        "thumbnailImageUrl": "https://www.di.ens.fr/willow/research/howto100m/web-dist/images/new_dataset2.png",
	"paperUrl": "https://arxiv.org/pdf/1906.03327",
        "publishedYear": 2019,
        "type": "Captioning",
        "numberOfVideos": 1200000,
        "annotation": "120M clip-captions",
        "annotationType": ["captions"],
        "comment": "..."
    },	
	{
        "datasetId": 5039,
        "datasetTitle": "Oops!",
        "datasetDescription": "Predicting Unintentional Action in Video",
        "websiteUrl": "https://oops.cs.columbia.edu/",
        "thumbnailImageUrl": "https://oops.cs.columbia.edu/teaser.svg",
	"paperUrl": "https://arxiv.org/abs/1911.11206",
        "publishedYear": 2019,
        "type": "Classification",
        "numberOfVideos": 20723,
        "annotation": "Intentionality label of action and localization of transition from unintentional to intentional",
        "annotationType": ["pre-defined classes"],
        "comment": "..."
    },	
	{
        "datasetId": 5040,
        "datasetTitle": "MovieNet",
        "datasetDescription": "A holistic dataset for movie understanding",
        "websiteUrl": "http://movienet.site/",
        "thumbnailImageUrl": "http://movienet.site/src/imgs/pub/eccv20movienet.jpg",
	"paperUrl": "https://arxiv.org/abs/2007.10937",
        "publishedYear": 2020,
        "type": "Classification, Detection, Captioning",
        "numberOfVideos": 42000,
        "annotation": "1.1k movies, 60K trailers, 375K metadata, 1.1M instances of 3087 unique credited cast, 42K scenes, 45K action tags",
        "annotationType": ["pre-defined classes, captions"],
        "comment": "..."
    }






]
